# -*- coding: utf-8 -*-
"""main.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dVAG4-QLuAKeSrZ27CKsEJTT_7G6eglR
"""

!pip install ultralytics

!pip install easyocr

!pip install ultralytics easyocr opencv-python-headless numpy

import cv2
import numpy as np
from ultralytics import YOLO
import easyocr
import re
from collections import defaultdict, deque
from google.colab.patches import cv2_imshow
from IPython.display import Video

# Load fine-tuned YOLO model and OCR reader
model = YOLO('license_plate_best.pt')
reader = easyocr.Reader(['en'], gpu=True)  # Use gpu=False if no GPU

# License plate pattern (e.g., AA11AAA)
plate_pattern = re.compile(r'[A-Z]{2}[0-9]{2}[A-Z]{3}')

# Correct common OCR errors
def correct_plate_format(ocr_text):
    mapping_num_to_alpha = {'0': 'O', '1': 'I', '2': 'Z', '3': 'B', '4': 'A', '5': 'S', '6': 'G', '7': 'T', '8': 'B', '9': 'P'}
    mapping_alpha_to_num = {'O': '0', 'I': '1', 'Z': '2', 'B': '3', 'A': '4', 'S': '5', 'G': '6', 'T': '7', 'P': '9', 'Q': '0'}

    ocr_text = ocr_text.upper().replace(' ', '')
    if len(ocr_text) == 7:
        return ocr_text

    corrected = []
    for i, ch in enumerate(ocr_text):
        if i < 2 or i > 3:  # Positions for letters
            if ch.isdigit():
                corrected.append(mapping_num_to_alpha.get(ch, ch))
            else:
                corrected.append(ch)
        else:  # Positions for numbers
            if ch.isalpha():
                corrected.append(mapping_alpha_to_num.get(ch, ch))
            else:
                corrected.append(ch)

    return ''.join(corrected) if len(corrected) == 7 else ''

# OCR with preprocessing
def recognize_plate(plate_crop):
    if plate_crop.size == 0:
        return ''

    gray = cv2.cvtColor(plate_crop, cv2.COLOR_BGR2GRAY)
    thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]
    plate_resized = cv2.resize(thresh, None, fx=2, fy=2, interpolation=cv2.INTER_CUBIC)

    try:
        ocr_result = reader.readtext(plate_resized, detail=0, allowlist='ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789')
        if ocr_result:
            candidate = correct_plate_format(ocr_result[0])
            if candidate and plate_pattern.match(candidate):
                return candidate
    except:
        pass
    return ''

# Stabilization
plate_history = defaultdict(lambda: deque(maxlen=10))
plate_final = {}

def get_box_id(x1, y1, x2, y2):
    return f"{int(x1/10)}_{int(y1/10)}_{int(x2/10)}_{int(y2/10)}"

def get_stable_plate(box_id, new_text):
    if new_text:
        plate_history[box_id].append(new_text)
        most_common = max(set(plate_history[box_id]), key=plate_history[box_id].count)
        plate_final[box_id] = most_common
    return plate_final.get(box_id, '')

# Video input/output
input_video = "cars.mp4"
output_video = "output_with_license.mp4"

cap = cv2.VideoCapture(input_video)
fourcc = cv2.VideoWriter_fourcc(*'mp4v')
out = cv2.VideoWriter(output_video, fourcc, cap.get(cv2.CAP_PROP_FPS),
                      (int(cap.get(3)), int(cap.get(4))))

CONF_THRESH = 0.3

while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        break

    results = model(frame, verbose=False)

    for r in results:
        for box in r.boxes:
            conf = float(box.conf.cpu().numpy()[0])
            if conf < CONF_THRESH:
                continue

            x1, y1, x2, y2 = map(int, box.xyxy[0].cpu().numpy())
            plate_crop = frame[y1:y2, x1:x2]
            text = recognize_plate(plate_crop)
            box_id = get_box_id(x1, y1, x2, y2)
            stable_text = get_stable_plate(box_id, text)

            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 3)

            if plate_crop.size > 0:
                overlay_h, overlay_w = 150, 400
                plate_resized = cv2.resize(plate_crop, (overlay_w, overlay_h))
                oy1 = max(0, y1 - overlay_h - 40)
                ox1 = x1
                oy2, ox2 = oy1 + overlay_h, ox1 + overlay_w
                if oy2 <= frame.shape[0] and ox2 <= frame.shape[1]:
                    frame[oy1:oy2, ox1:ox2] = plate_resized

            if stable_text:
                cv2.putText(frame, stable_text, (x1, y1 - 20),
                            cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 0, 0), 6)
                cv2.putText(frame, stable_text, (x1, y1 - 20),
                            cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 255, 255), 3)

    out.write(frame)

cap.release()
out.release()

print("âœ… Annotated video saved as", output_video)

# Display video in Colab
Video(output_video, embed=True, width=640, height=480)